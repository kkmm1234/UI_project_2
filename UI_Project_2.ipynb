{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3913,
     "status": "ok",
     "timestamp": 1746808019754,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "5x4gtrdMFazU"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive, files\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import time\n",
    "\n",
    "student_id = 404488\n",
    "np.random.seed(student_id)\n",
    "tf.random.set_seed(student_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 115594,
     "status": "ok",
     "timestamp": 1746808135346,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "hKQbdmypIovr",
    "outputId": "27b40a29-8163-4099-8815-dd9c8c62c3a8"
   },
   "outputs": [],
   "source": [
    "drive.flush_and_unmount\n",
    "drive.mount('/content/drive')\n",
    "!unzip -q '/content/drive/MyDrive/rock-paper-scissors.zip' -d '/content/drive/MyDrive/gesture_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1746808135349,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "eVfnszjJX_o8"
   },
   "outputs": [],
   "source": [
    "#load images from properly formated directories\n",
    "data_dir = '/content/drive/MyDrive/gesture_dataset'\n",
    "train_dir = os.path.join(data_dir, 'Rock-Paper-Scissors', 'train')\n",
    "test_dir = os.path.join(data_dir, 'Rock-Paper-Scissors', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1542,
     "status": "ok",
     "timestamp": 1746808136893,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "TgvA3mXmb-Uj",
    "outputId": "e3487a0e-4c98-4b12-cf48-327c978c18e7"
   },
   "outputs": [],
   "source": [
    "img_height = 224\n",
    "img_width = 224\n",
    "batch_size = 32\n",
    "\n",
    "train_ds_full = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=None,\n",
    "    shuffle=False,\n",
    "    seed=student_id\n",
    ")\n",
    "\n",
    "test_ds_full = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=None,\n",
    "    shuffle=False,\n",
    "    seed=student_id\n",
    ")\n",
    "\n",
    "class_names = train_ds_full.class_names\n",
    "print(f\"Classes: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1546,
     "status": "ok",
     "timestamp": 1746808138441,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "6giR9xJRcSUu"
   },
   "outputs": [],
   "source": [
    "#combine into 1 dataset\n",
    "all_images = train_ds_full.concatenate(test_ds_full)\n",
    "#shuffle images\n",
    "all_images = all_images.shuffle(buffer_size=1000, seed=student_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7047,
     "status": "ok",
     "timestamp": 1746808145490,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "ztZmPg1mcue-",
    "outputId": "d8403959-07c3-40cc-94a6-3381d5f8e508"
   },
   "outputs": [],
   "source": [
    "#get total size\n",
    "total_size = len(list(all_images))\n",
    "print(f\"Total dataset size: {total_size}\")\n",
    "\n",
    "#get data set sizes\n",
    "train_size = int(0.7 * total_size)\n",
    "val_size = int(0.1 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "#create the splits\n",
    "train_ds = all_images.take(train_size).batch(batch_size)\n",
    "remaining = all_images.skip(train_size)\n",
    "val_ds = remaining.take(val_size).batch(batch_size)\n",
    "test_ds = remaining.skip(val_size).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1746808145530,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "vcQN6xd5TysX",
    "outputId": "947a892b-c2ec-46d2-a5ec-5e8c2df7c6b5"
   },
   "outputs": [],
   "source": [
    "print(\"Data set sizes:\")\n",
    "print(f\"Training set: {tf.data.experimental.cardinality(train_ds)}\")\n",
    "print(f\"Validation set: {tf.data.experimental.cardinality(val_ds)}\")\n",
    "print(f\"Test set: {tf.data.experimental.cardinality(test_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 657
    },
    "executionInfo": {
     "elapsed": 11501,
     "status": "ok",
     "timestamp": 1746808157034,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "moerUWj8hWux",
    "outputId": "95220df8-5ba0-4461-bc07-1658fc89bdd5"
   },
   "outputs": [],
   "source": [
    "#visualise sample images\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.suptitle(\"Sample Images from Rock-Paper-Scissors Dataset\")\n",
    "\n",
    "#get a batch of images from the training dataset\n",
    "for images, labels in train_ds.take(50):\n",
    "    for i in range(min(9, len(images))):\n",
    "        plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.axis(\"off\")\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12186,
     "status": "ok",
     "timestamp": 1746808169238,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "LWQeDLusiqkJ"
   },
   "outputs": [],
   "source": [
    "#visualise class distribution\n",
    "def count_examples_per_class(dataset):\n",
    "    class_counts = [0] * len(class_names)\n",
    "    for _, labels in dataset:\n",
    "        for label in labels:\n",
    "            class_counts[label] += 1\n",
    "    return class_counts\n",
    "\n",
    "#calculate class distribution in each split\n",
    "train_counts = count_examples_per_class(train_ds)\n",
    "val_counts = count_examples_per_class(val_ds)\n",
    "test_counts = count_examples_per_class(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "executionInfo": {
     "elapsed": 138,
     "status": "ok",
     "timestamp": 1746808169378,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "QclGP-WujGDz",
    "outputId": "314c19f7-cf8d-4363-d1c2-501fe863ee3c"
   },
   "outputs": [],
   "source": [
    "# Plot class distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.suptitle(\"Class Distribution Across Datasets\")\n",
    "x = np.arange(len(class_names))\n",
    "width = 0.25\n",
    "\n",
    "plt.bar(x - width, train_counts, width, label='Training')\n",
    "plt.bar(x, val_counts, width, label='Validation')\n",
    "plt.bar(x + width, test_counts, width, label='Test')\n",
    "\n",
    "plt.xlabel('Class', fontsize=14)\n",
    "plt.ylabel('Number of Images', fontsize=14)\n",
    "plt.xticks(x, class_names, fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "executionInfo": {
     "elapsed": 4364,
     "status": "ok",
     "timestamp": 1746808173745,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "qXB4UO3pkfNe",
    "outputId": "e170e1bc-13b7-4e82-ca65-079843388b54"
   },
   "outputs": [],
   "source": [
    "#visualize image characteristics (RGB channels)\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.suptitle(\"RGB Channel Analysis of Sample Images\")\n",
    "\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(3):\n",
    "        img = images[i].numpy().astype(\"uint8\")\n",
    "        class_label = class_names[labels[i]]\n",
    "\n",
    "        plt.subplot(1, 3, i+1)\n",
    "\n",
    "        #plot RGB histograms\n",
    "        for j, color in enumerate(['red', 'green', 'blue']):\n",
    "            histogram = plt.hist(img[:,:,j].flatten(), bins=256, alpha=0.5, color=color, label=color)\n",
    "\n",
    "        plt.title(f\"{class_label}\")\n",
    "        plt.xlabel(\"Pixel Value\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        if i == 0:\n",
    "            plt.legend()\n",
    "        plt.ylim(0, 1500)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WldYZyBL5ai5"
   },
   "source": [
    "# 3 initial models\n",
    "Here we test 3 models a baseline a deeper model and a wider model to see which generalises better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3sgzfkvX5qr3"
   },
   "source": [
    "## Basline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "executionInfo": {
     "elapsed": 694,
     "status": "ok",
     "timestamp": 1746808174441,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "00lmib6LnNnq",
    "outputId": "cc587745-0606-4adc-a347-604d3f53ff43"
   },
   "outputs": [],
   "source": [
    "#simple baseline CNN\n",
    "baseline_model = models.Sequential([\n",
    "    #first convolutional block\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    #second convolutional block\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    #flatten and dense layers\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#compile model\n",
    "baseline_model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"baseline CNN architecture\")\n",
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 144846,
     "status": "ok",
     "timestamp": 1746808319289,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "oZtNViEhoJkd",
    "outputId": "f39c3e41-5027-447a-cfcf-96319689d0ef"
   },
   "outputs": [],
   "source": [
    "#train the model\n",
    "#callback for early stopping\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "print(\"Baseline model\")\n",
    "start_time = time.time()\n",
    "baseline_history = baseline_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "baseline_time = time.time() - start_time\n",
    "print(f\"\\nBaseline train time: {baseline_time} seconds\")\n",
    "\n",
    "baseline_val_loss, baseline_val_acc = baseline_model.evaluate(val_ds)\n",
    "print(f\"Baseline model val accuracy: {baseline_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0SvGxglr5ubX"
   },
   "source": [
    "## Deeper Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "executionInfo": {
     "elapsed": 117,
     "status": "ok",
     "timestamp": 1746808319432,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "p84C6gqZtZpj",
    "outputId": "baec6abf-2f08-4d42-c3d2-aea4cf80e093"
   },
   "outputs": [],
   "source": [
    "#create a deeper CNN model\n",
    "deeper_model = models.Sequential([\n",
    "    #first convolutional block\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    #second convolutional block\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    #third convolutional block\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#compile the model\n",
    "deeper_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "#print model summary\n",
    "print(\"Deeper CNN Architecture:\")\n",
    "deeper_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 224271,
     "status": "ok",
     "timestamp": 1746808543706,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "NM1ua6BytcQc",
    "outputId": "35404417-6b91-421e-c369-03a26338e6ef"
   },
   "outputs": [],
   "source": [
    "#train the deeper model\n",
    "print(\"Deeper model\")\n",
    "start_time = time.time()\n",
    "\n",
    "deeper_history = deeper_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "deeper_training_time = time.time() - start_time\n",
    "print(f\"\\nDeeper model training time: {deeper_training_time:.2f} seconds\")\n",
    "\n",
    "#evaluate on validation set\n",
    "deeper_val_loss, deeper_val_acc = deeper_model.evaluate(val_ds)\n",
    "print(f\"Deeper model validation accuracy: {deeper_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-deh1mXv5xYn"
   },
   "source": [
    "## Wider model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "executionInfo": {
     "elapsed": 64,
     "status": "ok",
     "timestamp": 1746808543785,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "OBAvzU9YuI2q",
    "outputId": "ae5eb28a-0b71-4b0a-a6fb-3277792d22fd"
   },
   "outputs": [],
   "source": [
    "#wider CNN model\n",
    "wider_model = models.Sequential([\n",
    "    #first convolutional block with more filters\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    #second convolutional block with more filters\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    #flatten and wider dense layers\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#compile the model\n",
    "wider_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "#print model summary\n",
    "print(\"\\nWider CNN Architecture:\")\n",
    "wider_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 224181,
     "status": "ok",
     "timestamp": 1746808767969,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "8RYhyPPauQvd",
    "outputId": "b819891d-9a9b-4cbf-814f-724ebddfbd44"
   },
   "outputs": [],
   "source": [
    "#train the wider model\n",
    "print(\"Wider model\")\n",
    "start_time = time.time()\n",
    "\n",
    "wider_history = wider_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "wider_training_time = time.time() - start_time\n",
    "print(f\"\\nWider model training time: {wider_training_time:.2f} seconds\")\n",
    "\n",
    "#evaluate on validation set\n",
    "wider_val_loss, wider_val_acc = wider_model.evaluate(val_ds)\n",
    "print(f\"Wider model validation accuracy: {wider_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92pgkR4M53sE"
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 256,
     "status": "ok",
     "timestamp": 1746808768245,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "xbDp-la_zZ3P",
    "outputId": "8601f716-d9e4-4227-e1e9-1b0d4b62509a"
   },
   "outputs": [],
   "source": [
    "# Compare the three model architectures\n",
    "architecture_comparison = {\n",
    "    'Model': ['Baseline CNN', 'Deeper CNN', 'Wider CNN'],\n",
    "    'Validation Accuracy': [baseline_val_acc, deeper_val_acc, wider_val_acc],\n",
    "    'Training Time (s)': [baseline_time, deeper_training_time, wider_training_time]\n",
    "}\n",
    "\n",
    "# Create a bar chart to compare accuracies\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(architecture_comparison['Model'], architecture_comparison['Validation Accuracy'])\n",
    "plt.title('Validation Accuracy by Architecture')\n",
    "plt.xlabel('Model Architecture')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.ylim(0, 1)  # Set y-axis from 0 to 1 for accuracy\n",
    "\n",
    "# Create a bar chart to compare training times\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(architecture_comparison['Model'], architecture_comparison['Training Time (s)'])\n",
    "plt.title('Training Time by Architecture')\n",
    "plt.xlabel('Model Architecture')\n",
    "plt.ylabel('Training Time (seconds)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the comparison as a formatted table\n",
    "print(\"\\nModel Architecture Comparison:\")\n",
    "for i in range(len(architecture_comparison['Model'])):\n",
    "    model = architecture_comparison['Model'][i]\n",
    "    acc = architecture_comparison['Validation Accuracy'][i]\n",
    "    time = architecture_comparison['Training Time (s)'][i]\n",
    "    print(f\"{model}: Accuracy = {acc:.4f}, Training Time = {time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16554,
     "status": "ok",
     "timestamp": 1746808784802,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "BtDxG0pGzzVL",
    "outputId": "05063995-74d9-4b32-b7e7-09cf65784138"
   },
   "outputs": [],
   "source": [
    "test_loss_base, test_acc_base = baseline_model.evaluate(test_ds)\n",
    "test_loss_deep, test_acc_deep = deeper_model.evaluate(test_ds)\n",
    "test_loss_wide, test_acc_wide = wider_model.evaluate(test_ds)\n",
    "\n",
    "print(\"Test accuracy for each model\")\n",
    "print(f\"Baseline Model: {test_acc_base}\")\n",
    "print(f\"Deeper Model: {test_acc_deep}\")\n",
    "print(f\"Wider Model: {test_acc_wide}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "executionInfo": {
     "elapsed": 151,
     "status": "ok",
     "timestamp": 1746808784955,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "umoVZ06l2nWQ",
    "outputId": "df7b4b28-da7b-4ab7-ebbd-c831404f2940"
   },
   "outputs": [],
   "source": [
    "models = ['Baseline Model', 'Deeper Model', 'Wider Model']\n",
    "test_acc = [test_acc_base, test_acc_deep, test_acc_wide]\n",
    "val_acc = [baseline_val_acc, deeper_val_acc, wider_val_acc]\n",
    "\n",
    "barWidth = 0.3\n",
    "#set bar positions\n",
    "r1 = np.arange(len(models))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "\n",
    "#create the grouped bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(r1, test_acc, width=barWidth, label='Test Accuracy', color='blue')\n",
    "plt.bar(r2, val_acc, width=barWidth, label='Validation Accuracy', color='orange')\n",
    "\n",
    "#add labels and title\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Test and Validation Accuracy Comparison')\n",
    "plt.xticks([r + barWidth/2 for r in range(len(models))], models)\n",
    "plt.ylim(0, 1.1)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "#add grid\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DANqoyT9wXcH"
   },
   "source": [
    "## Test on own images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "executionInfo": {
     "elapsed": 40567,
     "status": "ok",
     "timestamp": 1746809022063,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "YUBCeCluwbWF",
    "outputId": "ac261b60-40f4-48a6-92d5-135e3a063f68"
   },
   "outputs": [],
   "source": [
    "# Create the directory if it doesn't exist\n",
    "!mkdir -p /content/my_test_images\n",
    "\n",
    "# Upload images\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Save each file with its original name and extension\n",
    "for fn in uploaded.keys():\n",
    "   os.rename(fn, f'/content/my_test_images/{fn}')\n",
    "   print(f\"Saved {fn} to /content/my_test_images/{fn}\")\n",
    "\n",
    "# Verify the uploads worked\n",
    "image_files = [f for f in os.listdir('/content/my_test_images')\n",
    "              if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "print(f\"\\nFound {len(image_files)} image files in /content/my_test_images:\")\n",
    "for img in image_files:\n",
    "    print(f\"- {img}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1746809035418,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "DkZJvMFp0ccv",
    "outputId": "d3d9a09e-c179-4051-bd1a-d438b28b7d7a"
   },
   "outputs": [],
   "source": [
    "# Check if the folder exists\n",
    "folder_path = '/content/my_test_images'\n",
    "print(f\"Folder exists: {os.path.exists(folder_path)}\")\n",
    "\n",
    "# List contents of the parent directory to verify the folder name\n",
    "parent_dir = os.path.dirname(folder_path)\n",
    "print(f\"Contents of {parent_dir}:\")\n",
    "print(os.listdir(parent_dir))\n",
    "\n",
    "# If the folder exists, list its contents\n",
    "if os.path.exists(folder_path):\n",
    "    print(f\"\\nContents of {folder_path}:\")\n",
    "    files = os.listdir(folder_path)\n",
    "    print(files)\n",
    "\n",
    "    # Check file extensions\n",
    "    print(\"\\nFile extensions:\")\n",
    "    for file in files:\n",
    "        _, ext = os.path.splitext(file)\n",
    "        print(f\"{file}: {ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 843
    },
    "executionInfo": {
     "elapsed": 1715,
     "status": "ok",
     "timestamp": 1746809064350,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "AfkY2mlpw2vG",
    "outputId": "b10e5358-919a-4dee-f7ed-493dda376e39"
   },
   "outputs": [],
   "source": [
    "# Define variables\n",
    "model = baseline_model  # Or whichever model you want to test\n",
    "image_folder = '/content/my_test_images'  # Path to your test images folder\n",
    "class_names = ['paper', 'rock', 'scissors']  # Make sure these match your model's classes\n",
    "image_size = (224, 224)  # Size to resize images to\n",
    "\n",
    "# Get all image files\n",
    "image_files = [f for f in os.listdir(image_folder)\n",
    "              if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "print(f\"Found {len(image_files)} image files: {image_files}\")\n",
    "\n",
    "if not image_files:\n",
    "    print(f\"No images found in {image_folder}\")\n",
    "else:\n",
    "    # Set up the plot\n",
    "    n_images = len(image_files)\n",
    "    fig = plt.figure(figsize=(15, 4 * n_images))\n",
    "\n",
    "    # Process each image\n",
    "    for i, img_file in enumerate(image_files):\n",
    "        # Load and preprocess image\n",
    "        img_path = os.path.join(image_folder, img_file)\n",
    "        img = image.load_img(img_path, target_size=image_size)\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = img_array / 255.0  # Normalize to [0,1]\n",
    "        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "\n",
    "        # Make prediction\n",
    "        predictions = model.predict(img_array, verbose=0)\n",
    "        predicted_class_idx = np.argmax(predictions[0])\n",
    "        predicted_class = class_names[predicted_class_idx]\n",
    "        confidence = predictions[0][predicted_class_idx] * 100\n",
    "\n",
    "        # Display image and prediction\n",
    "        plt.subplot(n_images, 2, i*2 + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"File: {img_file}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Display prediction details\n",
    "        plt.subplot(n_images, 2, i*2 + 2)\n",
    "        # Create bar chart of predictions\n",
    "        bars = plt.bar(class_names, predictions[0])\n",
    "        bars[predicted_class_idx].set_color('red')\n",
    "        plt.ylim([0, 1.0])\n",
    "        plt.title(f\"Prediction: {predicted_class} ({confidence:.1f}%)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQQs9Zss6oG2"
   },
   "source": [
    "# Hyperparameters\n",
    "here we apply different hyperparameters to each model to see if we can improve the models further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_eZNJK8H6yYr"
   },
   "source": [
    "## Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LbSrbqa664ED",
    "outputId": "eb1deacc-172f-443c-de85-35e35282d761"
   },
   "outputs": [],
   "source": [
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "\n",
    "lr_results = {}\n",
    "\n",
    "for model_name, model_architecture in [\n",
    "    (\"baseline\", baseline_model),\n",
    "    (\"deeper\", deeper_model),\n",
    "    (\"wider\", wider_model)\n",
    "]:\n",
    "\n",
    "  print(f\"\\ntesting lr for {model_name} model\")\n",
    "\n",
    "  model_results = {}\n",
    "  for lr in learning_rates:\n",
    "    print(f\"testing lr: {lr}\")\n",
    "\n",
    "    if model_name == \"baseline\":\n",
    "      model = baseline_model\n",
    "    elif model_name == \"deeper\":\n",
    "      model = deeper_model\n",
    "    else:\n",
    "      model = wider_model\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=10,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(test_ds)\n",
    "\n",
    "    model_results[lr] = {\n",
    "       'test_accuracy': test_acc,\n",
    "       'history': history.history\n",
    "    }\n",
    "\n",
    "    print(f\"LR={lr}, Test accuracy={test_acc:.4f}\")\n",
    "\n",
    "  lr_results[model_name] = model_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 961349,
     "status": "aborted",
     "timestamp": 1746808977132,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "6BBx92usRoz7"
   },
   "outputs": [],
   "source": [
    "#visualise learning rate results\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, model_name in enumerate(lr_results.keys()):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "\n",
    "    for lr, results in lr_results[model_name].items():\n",
    "        plt.plot(results['history']['val_accuracy'], label=f'LR={lr}')\n",
    "\n",
    "    plt.title(f'{model_name} Model')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Effect of Learning Rate on Model Convergence', fontsize=16)\n",
    "plt.subplots_adjust(top=0.85)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 961391,
     "status": "aborted",
     "timestamp": 1746808977179,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "LDH-TsBuSD92"
   },
   "outputs": [],
   "source": [
    "#create a bar chart of final test accuracies\n",
    "plt.figure(figsize=(12, 6))\n",
    "model_names = list(lr_results.keys())\n",
    "x = np.arange(len(model_names))\n",
    "width = 0.25\n",
    "\n",
    "for i, lr in enumerate(learning_rates):\n",
    "    accuracies = [lr_results[model][lr]['test_accuracy'] for model in model_names]\n",
    "    plt.bar(x + i*width, accuracies, width, label=f'LR={lr}')\n",
    "\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.title('Impact of Learning Rate on Test Accuracy')\n",
    "plt.xticks(x + width, model_names)\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.ylim(0, 1.1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP5tPrUK2/4lb6L+ays67x1",
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
