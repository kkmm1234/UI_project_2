{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3928,
     "status": "ok",
     "timestamp": 1746896055283,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "5x4gtrdMFazU"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive, files\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import time\n",
    "from tensorflow import keras\n",
    "\n",
    "student_id = 404488\n",
    "np.random.seed(student_id)\n",
    "tf.random.set_seed(student_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 104709,
     "status": "ok",
     "timestamp": 1746896160035,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "hKQbdmypIovr",
    "outputId": "ed5b2962-7dd4-4cfd-e0c0-472a8e6945af"
   },
   "outputs": [],
   "source": [
    "drive.flush_and_unmount\n",
    "drive.mount('/content/drive')\n",
    "!unzip -q '/content/drive/MyDrive/rock-paper-scissors.zip' -d '/content/drive/MyDrive/gesture_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1746896160046,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "eVfnszjJX_o8"
   },
   "outputs": [],
   "source": [
    "#load images from properly formated directories\n",
    "data_dir = '/content/drive/MyDrive/gesture_dataset'\n",
    "train_dir = os.path.join(data_dir, 'Rock-Paper-Scissors', 'train')\n",
    "test_dir = os.path.join(data_dir, 'Rock-Paper-Scissors', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1742,
     "status": "ok",
     "timestamp": 1746896161794,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "TgvA3mXmb-Uj",
    "outputId": "9f226bb4-713c-4aab-f603-f17815ab3153"
   },
   "outputs": [],
   "source": [
    "img_height = 224\n",
    "img_width = 224\n",
    "batch_size = 32\n",
    "\n",
    "train_ds_full = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=None,\n",
    "    shuffle=False,\n",
    "    seed=student_id\n",
    ")\n",
    "\n",
    "test_ds_full = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=None,\n",
    "    shuffle=False,\n",
    "    seed=student_id\n",
    ")\n",
    "\n",
    "class_names = train_ds_full.class_names\n",
    "print(f\"Classes: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1637,
     "status": "ok",
     "timestamp": 1746896163434,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "6giR9xJRcSUu"
   },
   "outputs": [],
   "source": [
    "#combine into 1 dataset\n",
    "all_images = train_ds_full.concatenate(test_ds_full)\n",
    "#shuffle images\n",
    "all_images = all_images.shuffle(buffer_size=1000, seed=student_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7639,
     "status": "ok",
     "timestamp": 1746896171078,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "ztZmPg1mcue-",
    "outputId": "b001f6a4-4dd5-4ff7-ec0a-1396374fe0be"
   },
   "outputs": [],
   "source": [
    "#get total size\n",
    "total_size = len(list(all_images))\n",
    "print(f\"Total dataset size: {total_size}\")\n",
    "\n",
    "#get data set sizes\n",
    "train_size = int(0.7 * total_size)\n",
    "val_size = int(0.1 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "#create the splits\n",
    "train_ds = all_images.take(train_size).batch(batch_size)\n",
    "remaining = all_images.skip(train_size)\n",
    "val_ds = remaining.take(val_size).batch(batch_size)\n",
    "test_ds = remaining.skip(val_size).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1746896171094,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "vcQN6xd5TysX",
    "outputId": "f5bf8365-d10b-434d-b689-bb46241fd7b3"
   },
   "outputs": [],
   "source": [
    "print(\"Data set sizes:\")\n",
    "print(f\"Training set: {tf.data.experimental.cardinality(train_ds)}\")\n",
    "print(f\"Validation set: {tf.data.experimental.cardinality(val_ds)}\")\n",
    "print(f\"Test set: {tf.data.experimental.cardinality(test_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 657
    },
    "executionInfo": {
     "elapsed": 12283,
     "status": "ok",
     "timestamp": 1746896183385,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "moerUWj8hWux",
    "outputId": "ec133fb0-aac9-477c-b8f5-53619986170f"
   },
   "outputs": [],
   "source": [
    "#visualise sample images\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.suptitle(\"Sample Images from Rock-Paper-Scissors Dataset\")\n",
    "\n",
    "#get a batch of images from the training dataset\n",
    "for images, labels in train_ds.take(50):\n",
    "    for i in range(min(9, len(images))):\n",
    "        plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.axis(\"off\")\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12707,
     "status": "ok",
     "timestamp": 1746896196113,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "LWQeDLusiqkJ"
   },
   "outputs": [],
   "source": [
    "#visualise class distribution\n",
    "def count_examples_per_class(dataset):\n",
    "    class_counts = [0] * len(class_names)\n",
    "    for _, labels in dataset:\n",
    "        for label in labels:\n",
    "            class_counts[label] += 1\n",
    "    return class_counts\n",
    "\n",
    "#calculate class distribution in each split\n",
    "train_counts = count_examples_per_class(train_ds)\n",
    "val_counts = count_examples_per_class(val_ds)\n",
    "test_counts = count_examples_per_class(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "executionInfo": {
     "elapsed": 198,
     "status": "ok",
     "timestamp": 1746896196314,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "QclGP-WujGDz",
    "outputId": "3c711f2c-4e28-46af-b32a-acd94bea430f"
   },
   "outputs": [],
   "source": [
    "# Plot class distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.suptitle(\"Class Distribution Across Datasets\")\n",
    "x = np.arange(len(class_names))\n",
    "width = 0.25\n",
    "\n",
    "plt.bar(x - width, train_counts, width, label='Training')\n",
    "plt.bar(x, val_counts, width, label='Validation')\n",
    "plt.bar(x + width, test_counts, width, label='Test')\n",
    "\n",
    "plt.xlabel('Class', fontsize=14)\n",
    "plt.ylabel('Number of Images', fontsize=14)\n",
    "plt.xticks(x, class_names, fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "executionInfo": {
     "elapsed": 4725,
     "status": "ok",
     "timestamp": 1746896201042,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "qXB4UO3pkfNe",
    "outputId": "c7456b4b-9900-4489-9c80-ba6bd6caf8d1"
   },
   "outputs": [],
   "source": [
    "#visualise image characteristics\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.suptitle(\"RGB Channel Analysis of Sample Images\")\n",
    "\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(3):\n",
    "        img = images[i].numpy().astype(\"uint8\")\n",
    "        class_label = class_names[labels[i]]\n",
    "\n",
    "        plt.subplot(1, 3, i+1)\n",
    "\n",
    "        #plot RGB histograms\n",
    "        for j, color in enumerate(['red', 'green', 'blue']):\n",
    "            histogram = plt.hist(img[:,:,j].flatten(), bins=256, alpha=0.5, color=color, label=color)\n",
    "\n",
    "        plt.title(f\"{class_label}\")\n",
    "        plt.xlabel(\"Pixel Value\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        if i == 0:\n",
    "            plt.legend()\n",
    "        plt.ylim(0, 1500)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WldYZyBL5ai5"
   },
   "source": [
    "# 3 initial models\n",
    "Here we test 3 models a baseline a deeper model and a wider model to see which generalises better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3sgzfkvX5qr3"
   },
   "source": [
    "## Basline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1746896201058,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "cI7e8cs7G4BX"
   },
   "outputs": [],
   "source": [
    "#create a callback for early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "executionInfo": {
     "elapsed": 700,
     "status": "ok",
     "timestamp": 1746896201755,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "00lmib6LnNnq",
    "outputId": "26ca7461-e956-49d4-f1c8-aa94920322d5"
   },
   "outputs": [],
   "source": [
    "#create a simple baseline CNN\n",
    "baseline_model = models.Sequential([\n",
    "    #first convolutional block\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    #second convolutional block\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    #flatten and dense layers\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')  # 3 classes: rock, paper, scissors\n",
    "])\n",
    "\n",
    "#compile the model\n",
    "baseline_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "#print model summary\n",
    "print(\"Baseline CNN Architecture:\")\n",
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 155467,
     "status": "ok",
     "timestamp": 1746896357224,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "oZtNViEhoJkd",
    "outputId": "950279e4-cea9-45c5-899c-b653809a9c9f"
   },
   "outputs": [],
   "source": [
    "#train the baseline model\n",
    "print(\"\\nTraining the baseline model...\")\n",
    "start_time = time.time()\n",
    "\n",
    "baseline_history = baseline_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "baseline_training_time = time.time() - start_time\n",
    "print(f\"\\nBaseline model training time: {baseline_training_time:.2f} seconds\")\n",
    "\n",
    "#evaluate on validation set\n",
    "baseline_val_loss, baseline_val_acc = baseline_model.evaluate(val_ds)\n",
    "print(f\"Baseline model validation accuracy: {baseline_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0SvGxglr5ubX"
   },
   "source": [
    "## Deeper Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "executionInfo": {
     "elapsed": 114,
     "status": "ok",
     "timestamp": 1746896357341,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "p84C6gqZtZpj",
    "outputId": "411f71a6-061e-49d1-fa34-ee30396f7416"
   },
   "outputs": [],
   "source": [
    "#create a deeper CNN model\n",
    "deeper_model = models.Sequential([\n",
    "    #first convolutional block\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    #second convolutional block\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    #third convolutional block\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    #flatten and dense layers\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#compile the model\n",
    "deeper_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "#print model summary\n",
    "print(\"Deeper CNN Architecture:\")\n",
    "deeper_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 243722,
     "status": "ok",
     "timestamp": 1746896601067,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "NM1ua6BytcQc",
    "outputId": "0105e82a-360c-4f01-a563-7e2c074f1efa"
   },
   "outputs": [],
   "source": [
    "#train the deeper model\n",
    "print(\"\\nTraining the deeper model...\")\n",
    "start_time = time.time()\n",
    "\n",
    "deeper_history = deeper_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "deeper_training_time = time.time() - start_time\n",
    "print(f\"\\nDeeper model training time: {deeper_training_time:.2f} seconds\")\n",
    "\n",
    "#evaluate on validation set\n",
    "deeper_val_loss, deeper_val_acc = deeper_model.evaluate(val_ds)\n",
    "print(f\"Deeper model validation accuracy: {deeper_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-deh1mXv5xYn"
   },
   "source": [
    "## Wider model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1746896601142,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "OBAvzU9YuI2q",
    "outputId": "f376d245-5816-43da-e7b1-fa4661a0ed10"
   },
   "outputs": [],
   "source": [
    "#create a wider CNN model\n",
    "wider_model = models.Sequential([\n",
    "    #first convolutional block with more filters\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    #second convolutional block with more filters\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    #flatten and wider dense layers\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#compile the model\n",
    "wider_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "#print model summary\n",
    "print(\"\\nWider CNN Architecture:\")\n",
    "wider_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 227857,
     "status": "ok",
     "timestamp": 1746896829003,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "8RYhyPPauQvd",
    "outputId": "f0373b21-49b4-45f0-a2b2-67fd09119868"
   },
   "outputs": [],
   "source": [
    "#train the wider model\n",
    "print(\"\\nTraining the wider model...\")\n",
    "start_time = time.time()\n",
    "\n",
    "wider_history = wider_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "wider_training_time = time.time() - start_time\n",
    "print(f\"\\nWider model training time: {wider_training_time:.2f} seconds\")\n",
    "\n",
    "#evaluate on validation set\n",
    "wider_val_loss, wider_val_acc = wider_model.evaluate(val_ds)\n",
    "print(f\"Wider model validation accuracy: {wider_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92pgkR4M53sE"
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 278,
     "status": "ok",
     "timestamp": 1746896829318,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "xbDp-la_zZ3P",
    "outputId": "106bf37f-7880-40f3-867b-5ad4ab2d9ba6"
   },
   "outputs": [],
   "source": [
    "#compare the three model architectures\n",
    "architecture_comparison = {\n",
    "    'Model': ['Baseline CNN', 'Deeper CNN', 'Wider CNN'],\n",
    "    'Validation Accuracy': [baseline_val_acc, deeper_val_acc, wider_val_acc],\n",
    "    'Training Time (s)': [baseline_training_time, deeper_training_time, wider_training_time]\n",
    "}\n",
    "\n",
    "#create a bar chart to compare accuracies\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(architecture_comparison['Model'], architecture_comparison['Validation Accuracy'])\n",
    "plt.title('Validation Accuracy by Architecture')\n",
    "plt.xlabel('Model Architecture')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "#create a bar chart to compare training times\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(architecture_comparison['Model'], architecture_comparison['Training Time (s)'])\n",
    "plt.title('Training Time by Architecture')\n",
    "plt.xlabel('Model Architecture')\n",
    "plt.ylabel('Training Time (seconds)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#print the comparison as a formatted table\n",
    "print(\"\\nModel Architecture Comparison:\")\n",
    "for i in range(len(architecture_comparison['Model'])):\n",
    "    model = architecture_comparison['Model'][i]\n",
    "    acc = architecture_comparison['Validation Accuracy'][i]\n",
    "    time = architecture_comparison['Training Time (s)'][i]\n",
    "    print(f\"{model}: Accuracy = {acc:.4f}, Training Time = {time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17043,
     "status": "ok",
     "timestamp": 1746896846374,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "BtDxG0pGzzVL",
    "outputId": "c5e8e0bb-ea8f-4d12-a3d9-641fe07a36de"
   },
   "outputs": [],
   "source": [
    "test_loss_base, test_acc_base = baseline_model.evaluate(test_ds)\n",
    "test_loss_deep, test_acc_deep = deeper_model.evaluate(test_ds)\n",
    "test_loss_wide, test_acc_wide = wider_model.evaluate(test_ds)\n",
    "\n",
    "print(\"Test accuracy for each model\")\n",
    "print(f\"Baseline Model: {test_acc_base}\")\n",
    "print(f\"Deeper Model: {test_acc_deep}\")\n",
    "print(f\"Wider Model: {test_acc_wide}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "executionInfo": {
     "elapsed": 234,
     "status": "ok",
     "timestamp": 1746896846611,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "umoVZ06l2nWQ",
    "outputId": "f0de2110-0f38-4bcd-862f-00e8a26e0cba"
   },
   "outputs": [],
   "source": [
    "model_names = ['Baseline Model', 'Deeper Model', 'Wider Model']\n",
    "test_acc = [test_acc_base, test_acc_deep, test_acc_wide]\n",
    "val_acc = [baseline_val_acc, deeper_val_acc, wider_val_acc]\n",
    "\n",
    "barWidth = 0.3\n",
    "#set bar positions\n",
    "r1 = np.arange(len(model_names))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "\n",
    "#create the grouped bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(r1, test_acc, width=barWidth, label='Test Accuracy', color='blue')\n",
    "plt.bar(r2, val_acc, width=barWidth, label='Validation Accuracy', color='orange')\n",
    "\n",
    "#add labels and title\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Test and Validation Accuracy Comparison')\n",
    "plt.xticks([r + barWidth/2 for r in range(len(model_names))], model_names)\n",
    "plt.ylim(0, 1.1)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "#add grid\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DANqoyT9wXcH"
   },
   "source": [
    "## Test on own images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "executionInfo": {
     "elapsed": 44281,
     "status": "ok",
     "timestamp": 1746896890896,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "YUBCeCluwbWF",
    "outputId": "4912e1f3-a144-416d-abb2-c30b2f729db5"
   },
   "outputs": [],
   "source": [
    "# Create the directory if it doesn't exist\n",
    "!mkdir -p /content/my_test_images\n",
    "\n",
    "# Upload images\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Save each file with its original name and extension\n",
    "for fn in uploaded.keys():\n",
    "   os.rename(fn, f'/content/my_test_images/{fn}')\n",
    "   print(f\"Saved {fn} to /content/my_test_images/{fn}\")\n",
    "\n",
    "# Verify the uploads worked\n",
    "image_files = [f for f in os.listdir('/content/my_test_images')\n",
    "              if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "print(f\"\\nFound {len(image_files)} image files in /content/my_test_images:\")\n",
    "for img in image_files:\n",
    "    print(f\"- {img}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1746896890942,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "DkZJvMFp0ccv",
    "outputId": "0fd04ae2-c568-4ba7-da85-81c9be35d341"
   },
   "outputs": [],
   "source": [
    "# Check if the folder exists\n",
    "folder_path = '/content/my_test_images'\n",
    "print(f\"Folder exists: {os.path.exists(folder_path)}\")\n",
    "\n",
    "# List contents of the parent directory to verify the folder name\n",
    "parent_dir = os.path.dirname(folder_path)\n",
    "print(f\"Contents of {parent_dir}:\")\n",
    "print(os.listdir(parent_dir))\n",
    "\n",
    "# If the folder exists, list its contents\n",
    "if os.path.exists(folder_path):\n",
    "    print(f\"\\nContents of {folder_path}:\")\n",
    "    files = os.listdir(folder_path)\n",
    "    print(files)\n",
    "\n",
    "    # Check file extensions\n",
    "    print(\"\\nFile extensions:\")\n",
    "    for file in files:\n",
    "        _, ext = os.path.splitext(file)\n",
    "        print(f\"{file}: {ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1N5S1KEm8692lUB1e2osxyJsacKbZDvl4"
    },
    "executionInfo": {
     "elapsed": 6000,
     "status": "ok",
     "timestamp": 1746896896949,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "AfkY2mlpw2vG",
    "outputId": "76352e0e-9196-48aa-f2b4-3330e6afc3dd"
   },
   "outputs": [],
   "source": [
    "# Define variables\n",
    "models_types  = [baseline_model, deeper_model, wider_model]\n",
    "names = ['Baseline', 'Deeper', 'Wider']\n",
    "image_folder = '/content/my_test_images'  # Path to your test images folder\n",
    "class_names = ['paper', 'rock', 'scissors']  # Make sure these match your model's classes\n",
    "image_size = (224, 224)  # Size to resize images to\n",
    "\n",
    "# Get all image files\n",
    "image_files = [f for f in os.listdir(image_folder)\n",
    "              if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "print(f\"Found {len(image_files)} image files: {image_files}\")\n",
    "\n",
    "if not image_files:\n",
    "    print(f\"No images found in {image_folder}\")\n",
    "else:\n",
    "  for model, name in zip(models_types, names):\n",
    "      # Set up the plot\n",
    "      n_images = len(image_files)\n",
    "      fig = plt.figure(figsize=(15, 4 * n_images))\n",
    "\n",
    "      # Process each image\n",
    "      plt.title(f\"Model: {name}\")\n",
    "      for i, img_file in enumerate(image_files):\n",
    "          # Load and preprocess image\n",
    "          img_path = os.path.join(image_folder, img_file)\n",
    "          img = image.load_img(img_path, target_size=image_size)\n",
    "          img_array = image.img_to_array(img)\n",
    "          img_array = img_array / 255.0  # Normalize to [0,1]\n",
    "          img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "\n",
    "          # Make prediction\n",
    "          predictions = model.predict(img_array, verbose=0)\n",
    "          predicted_class_idx = np.argmax(predictions[0])\n",
    "          predicted_class = class_names[predicted_class_idx]\n",
    "          confidence = predictions[0][predicted_class_idx] * 100\n",
    "\n",
    "          # Display image and prediction\n",
    "          plt.subplot(n_images, 2, i*2 + 1)\n",
    "          plt.imshow(img)\n",
    "          plt.title(f\"File: {img_file}\")\n",
    "          plt.axis('off')\n",
    "\n",
    "          # Display prediction details\n",
    "          plt.subplot(n_images, 2, i*2 + 2)\n",
    "          # Create bar chart of predictions\n",
    "          bars = plt.bar(class_names, predictions[0])\n",
    "          bars[predicted_class_idx].set_color('red')\n",
    "          plt.ylim([0, 1.0])\n",
    "          plt.title(f\"Prediction: {predicted_class} ({confidence:.1f}%)\")\n",
    "\n",
    "      plt.tight_layout()\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 5690,
     "status": "ok",
     "timestamp": 1746896902693,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "dr3rDFSFN8LG",
    "outputId": "611763d5-fbd1-49a1-c57b-00931e75fbdd"
   },
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.3),  # More rotation\n",
    "    layers.RandomZoom(0.3),      # More zoom\n",
    "    layers.RandomBrightness(0.4), # More brightness variation\n",
    "    layers.RandomContrast(0.3),   # More contrast variation\n",
    "    layers.RandomTranslation(0.2, 0.2)  # Add translation\n",
    "])\n",
    "\n",
    "# Visualize the augmentation effects on some training images\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    # Display original images in first row\n",
    "    for i in range(min(9, len(images))):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Now show augmented versions\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    # Apply data augmentation\n",
    "    augmented_images = data_augmentation(images, training=True)\n",
    "    # Display augmented images\n",
    "    for i in range(min(9, len(augmented_images))):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(augmented_images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 266,
     "status": "ok",
     "timestamp": 1746896902969,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "MSFUb_YOO70l"
   },
   "outputs": [],
   "source": [
    "# Method 1: Apply augmentation to the dataset\n",
    "def apply_augmentation(images, labels):\n",
    "    # Apply augmentation only during training\n",
    "    augmented_images = data_augmentation(images, training=True)\n",
    "    return augmented_images, labels\n",
    "\n",
    "# Create an augmented training dataset\n",
    "augmented_train_ds = train_ds.map(\n",
    "    apply_augmentation,\n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "\n",
    "# Apply same optimizations as your original dataset\n",
    "augmented_train_ds = augmented_train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 95542,
     "status": "ok",
     "timestamp": 1746896998514,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "FrOa3ZtpPw7g",
    "outputId": "43f4ad83-f84b-4328-d301-49bbc78bed45"
   },
   "outputs": [],
   "source": [
    "#create a simple baseline CNN\n",
    "baseline_model = models.Sequential([\n",
    "    #first convolutional block\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    #second convolutional block\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    #flatten and dense layers\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')  # 3 classes: rock, paper, scissors\n",
    "])\n",
    "\n",
    "#compile the model\n",
    "baseline_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "baseline_history = baseline_model.fit(\n",
    "    augmented_train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "baseline_val_loss, baseline_val_acc = baseline_model.evaluate(val_ds)\n",
    "print(f\"Baseline model validation accuracy: {baseline_val_acc:.4f}\")\n",
    "\n",
    "baseline_test_loss, baseline_test_acc = baseline_model.evaluate(test_ds)\n",
    "print(f\"Baseline model test accuracy: {baseline_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 165890,
     "status": "ok",
     "timestamp": 1746897164406,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "Xvr2q878Phtu",
    "outputId": "54261691-f0ad-43cb-b0d7-faa6c2ed20a7"
   },
   "outputs": [],
   "source": [
    "#create a deeper CNN model\n",
    "deeper_model = models.Sequential([\n",
    "    #first convolutional block\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    #second convolutional block\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    #third convolutional block\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    #flatten and dense layers\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#compile the model\n",
    "deeper_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "deeper_history = deeper_model.fit(\n",
    "    augmented_train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "deeper_val_loss, deeper_val_acc = deeper_model.evaluate(val_ds)\n",
    "print(f\"Deeper model validation accuracy: {deeper_val_acc:.4f}\")\n",
    "\n",
    "deeper_test_loss, deeper_test_acc = deeper_model.evaluate(test_ds)\n",
    "print(f\"Deeper model test accuracy: {deeper_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 142434,
     "status": "ok",
     "timestamp": 1746897306843,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "EcO-uhciPVE5",
    "outputId": "5d54ed2c-3745-453a-ca00-f7b97263baa9"
   },
   "outputs": [],
   "source": [
    "#create a wider CNN model\n",
    "wider_model = models.Sequential([\n",
    "    #first convolutional block with more filters\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    #second convolutional block with more filters\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    #flatten and wider dense layers\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#compile the model\n",
    "wider_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "wider_history = wider_model.fit(\n",
    "    augmented_train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "wider_val_loss, wider_val_acc = wider_model.evaluate(val_ds)\n",
    "print(f\"Wider model validation accuracy: {wider_val_acc:.4f}\")\n",
    "\n",
    "wider_test_loss, wider_test_acc = wider_model.evaluate(test_ds)\n",
    "print(f\"Wider model test accuracy: {wider_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "executionInfo": {
     "elapsed": 147,
     "status": "ok",
     "timestamp": 1746897306993,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "mGgGc4w3RH9y",
    "outputId": "e8fa5b54-6285-4106-c6f4-0b8caa70a015"
   },
   "outputs": [],
   "source": [
    "model_names = ['Baseline Model', 'Deeper Model', 'Wider Model']\n",
    "test_acc = [baseline_test_acc, deeper_test_acc, wider_test_acc]\n",
    "val_acc = [baseline_val_acc, deeper_val_acc, wider_val_acc]\n",
    "\n",
    "barWidth = 0.3\n",
    "#set bar positions\n",
    "r1 = np.arange(len(model_names))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "\n",
    "#create the grouped bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(r1, test_acc, width=barWidth, label='Test Accuracy', color='blue')\n",
    "plt.bar(r2, val_acc, width=barWidth, label='Validation Accuracy', color='orange')\n",
    "\n",
    "#add labels and title\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Test and Validation Accuracy Comparison')\n",
    "plt.xticks([r + barWidth/2 for r in range(len(model_names))], model_names)\n",
    "plt.ylim(0, 1.1)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "#add grid\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "15DwFNnPxB7XIHi55LVwIVMQ5pyhbU1Zy"
    },
    "executionInfo": {
     "elapsed": 5717,
     "status": "ok",
     "timestamp": 1746897312716,
     "user": {
      "displayName": "Keith M",
      "userId": "12033836580644727059"
     },
     "user_tz": -60
    },
    "id": "RFktfR7CTRs3",
    "outputId": "6f3b01c0-eed0-4c8e-f1e5-be1e4e22a38f"
   },
   "outputs": [],
   "source": [
    "# Define variables\n",
    "model_types  = [baseline_model, deeper_model, wider_model]\n",
    "names = ['Baseline', 'Deeper', 'Wider']\n",
    "image_folder = '/content/my_test_images'  # Path to your test images folder\n",
    "class_names = ['paper', 'rock', 'scissors']  # Make sure these match your model's classes\n",
    "image_size = (224, 224)  # Size to resize images to\n",
    "\n",
    "# Get all image files\n",
    "image_files = [f for f in os.listdir(image_folder)\n",
    "              if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "print(f\"Found {len(image_files)} image files: {image_files}\")\n",
    "\n",
    "if not image_files:\n",
    "    print(f\"No images found in {image_folder}\")\n",
    "else:\n",
    "  for model, name in zip(model_types, names):\n",
    "      # Set up the plot\n",
    "      n_images = len(image_files)\n",
    "      fig = plt.figure(figsize=(15, 4 * n_images))\n",
    "\n",
    "      # Process each image\n",
    "      plt.title(f\"Model: {name}\")\n",
    "      for i, img_file in enumerate(image_files):\n",
    "          # Load and preprocess image\n",
    "          img_path = os.path.join(image_folder, img_file)\n",
    "          img = image.load_img(img_path, target_size=image_size)\n",
    "          img_array = image.img_to_array(img)\n",
    "          img_array = img_array / 255.0  # Normalize to [0,1]\n",
    "          img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "\n",
    "          # Make prediction\n",
    "          predictions = model.predict(img_array, verbose=0)\n",
    "          predicted_class_idx = np.argmax(predictions[0])\n",
    "          predicted_class = class_names[predicted_class_idx]\n",
    "          confidence = predictions[0][predicted_class_idx] * 100\n",
    "\n",
    "          # Display image and prediction\n",
    "          plt.subplot(n_images, 2, i*2 + 1)\n",
    "          plt.imshow(img)\n",
    "          plt.title(f\"File: {img_file}\")\n",
    "          plt.axis('off')\n",
    "\n",
    "          # Display prediction details\n",
    "          plt.subplot(n_images, 2, i*2 + 2)\n",
    "          # Create bar chart of predictions\n",
    "          bars = plt.bar(class_names, predictions[0])\n",
    "          bars[predicted_class_idx].set_color('red')\n",
    "          plt.ylim([0, 1.0])\n",
    "          plt.title(f\"Prediction: {predicted_class} ({confidence:.1f}%)\")\n",
    "\n",
    "      plt.tight_layout()\n",
    "      plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNPPhFlDLdA54dFeP2w9YVs",
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
